{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "$$ \\LaTeX \\text{ command declarations here.}\n",
    "\\newcommand{\\N}{\\mathcal{N}}\n",
    "\\newcommand{\\R}{\\mathbb{R}}\n",
    "\\renewcommand{\\vec}[1]{\\mathbf{#1}}\n",
    "\\newcommand{\\norm}[1]{\\|#1\\|_2}\n",
    "\\newcommand{\\d}{\\mathop{}\\!\\mathrm{d}}\n",
    "\\newcommand{\\qed}{\\qquad \\mathbf{Q.E.D.}}\n",
    "\\newcommand{\\vx}{\\mathbf{x}}\n",
    "\\newcommand{\\vy}{\\mathbf{y}}\n",
    "\\newcommand{\\vt}{\\mathbf{t}}\n",
    "\\newcommand{\\vb}{\\mathbf{b}}\n",
    "\\newcommand{\\vw}{\\mathbf{w}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from Lec06 import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# EECS 545:  Machine Learning\n",
    "## Lecture 6:  Bayesian Linear Regression & Gaussian Processes\n",
    "* Instructor:  **Jacob Abernethy**\n",
    "* Date:  February 17, 2015\n",
    "\n",
    "*Lecture Exposition Credit: Ben & Valli*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Outline for this Lecture\n",
    "- More on Multivariate Gaussian\n",
    "    - Partitioned Marginal in Multivariate Gaussian\n",
    "    - Conditional of Multivariate Gaussian \n",
    "    - Bayes' Theorem for Linear Gaussian System\n",
    "    \n",
    "- Bayesian Linear Regression\n",
    "    - Bayesian Linear Regression\n",
    "    - Sequential Bayesian Learning\n",
    "    \n",
    "- Gaussian Processes\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Reading List\n",
    "\n",
    "- Required:    \n",
    "    - **[PRML]**, §3.3: Bayesian Linear Regression\n",
    "    - **[PRML]**, §6.4: Gaussian Processes\n",
    "- Optional:\n",
    "    - **[MLAPP]**, §7.6.1-7.6.2: Bayesian Linear Regression\n",
    "    - **[MLAPP]**, §4.3: Inference in Joinly Gaussian Distributions\n",
    "    - **[CS229]** Ng, Andrew.  [CS 229:  Machine Learning](http://cs229.stanford.edu/).  Autumn 2015.\n",
    "        - [Gaussian Processes](http://cs229.stanford.edu/section/cs229-gaussian_processes.pdf)\n",
    "        - [More on Gaussians](http://cs229.stanford.edu/section/more_on_gaussians.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "> In this lecture, our main goal is to introduce linear regression from a Bayesian perspective which is an extension to last lecture. One important application of this is to let linear regression work in a *online* fashion.\n",
    "\n",
    "> Specifically, we will first cover some basics of multivariate Gaussians and derive the results of Bayes' Theorem for linear Gaussian system which will be used later. Next we will show how to do linear regression in Bayesian setting. Unlike finding a deterministic estimate of coefficients $\\vw$ in previous lectures, we will find a distribution of $\\vw$. Then, we will show how to apply Bayesian linear regression to streaming data. Streaming scenarios include realtime measurements, large amount of data that exceeds memory limit, etc.. Finally, we will introduce Gaussian processes and show Bayesian linear regression is actually a Gaussian process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## More on Multivariate Gaussians\n",
    "\n",
    "> Taken from **[PRML]** §2.3, **[MLAPP]** §4.3, 4.4, and **[CS229]**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Multivariate Gaussians: Basics\n",
    "\n",
    "- For **Multivariate Gaussian** distribution $\\vec{x} \\sim \\N(\\vec{\\mu}, \\Sigma)$, we have\n",
    "    - **mean** $\\vec{\\mu} \\in \\R^D$\n",
    "    - **covariance matrix** $\\Sigma \\in \\R^{D \\times D}$\n",
    "    - **PDF**\n",
    "    $$\n",
    "    \\N(\\vec{x} | \\vec{\\mu}, \\Sigma)\n",
    "    = \\frac{1}{\\sqrt{(2\\pi)^D \\det( \\Sigma )}} \\exp\\left[ -\\frac12 (\\vec{x}-\\mu)^T \\Sigma^{-1} (\\vec{x} - \\mu) \\right]\n",
    "    $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Partitioned Gaussian Distributions\n",
    "\n",
    "- Partition $\\vec{x} \\sim \\N(\\vec{\\mu}, \\Sigma)$ as\n",
    "    $$\n",
    "    \\vec{x} = \\begin{bmatrix}  \\vec{x_a} \\\\ \\vec{x_b} \\end{bmatrix}\n",
    "    \\quad\n",
    "    \\ \\vec{\\mu} = \\begin{bmatrix} \\vec{\\mu_a} \\\\ \\vec{\\mu_b} \\end{bmatrix}\n",
    "    \\quad\n",
    "    \\Sigma = \\begin{bmatrix}\n",
    "    \\Sigma_{aa} & \\Sigma_{ab} \\\\\n",
    "    \\Sigma_{ba} & \\Sigma_{bb}\n",
    "    \\end{bmatrix}\n",
    "    $$\n",
    "    such that $\\vec{x_a}, \\vec{\\mu_a} \\in \\R^{D_a}$, $\\vec{x_b}, \\vec{\\mu_b} \\in \\R^{D_b}$, $\\Sigma_{aa} \\in \\R^{D_a \\times D_a}$ and $\\Sigma_{bb} \\in \\R^{D_b \\times D_b}$ for some $D_a$ and $D_b$ ($D_a + D_b = D$).\n",
    "    \n",
    "- Then we could have marginals\n",
    "    $$\n",
    "    \\boxed{\\begin{matrix}\n",
    "    \\vec{x_a} \\sim \\N(\\vec{\\mu_a}, \\Sigma_{aa}) \\\\ \n",
    "    \\vec{x_b} \\sim \\N(\\vec{\\mu_b}, \\Sigma_{bb})\n",
    "    \\end{matrix}}\n",
    "    $$\n",
    "\n",
    "- Proof is in the **notes**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "> **Remark**—Proof for partitioned Gaussian Distribution\n",
    "\n",
    ">    - For covariance matrix $\\Sigma = \\begin{bmatrix} \\Sigma_{aa} & \\Sigma_{ab} \\\\ \\Sigma_{ba} & \\Sigma_{bb} \\end{bmatrix}$, define $\\Lambda = \\Sigma^{-1} = \\begin{bmatrix} \\Lambda_{aa} & \\Lambda_{ab} \\\\ \\Lambda_{ba} & \\Lambda_{bb} \\end{bmatrix}$\n",
    "\n",
    ">    - **Fact 1** Based on [blockwise inversion of matrix](https://en.wikipedia.org/wiki/Invertible_matrix#Blockwise_inversion), we have \n",
    "    $$\n",
    "    \\begin{align}\n",
    "    \\Lambda_{bb} &= (\\Sigma_{bb}-\\Sigma_{ba} \\Sigma_{aa}^{-1} \\Sigma_{ab})^{-1} \\\\\n",
    "    \\Lambda_{ba} &= -\\Lambda_{bb}\\Sigma_{ba}\\Sigma_{aa}^{-1} \\\\\n",
    "    \\Sigma_{aa} &= (\\Lambda_{aa}-\\Lambda_{ab} \\Lambda_{bb}^{-1} \\Lambda_{ba})^{-1}\n",
    "    \\end{align}\n",
    "    $$\n",
    "\n",
    ">    - **Fact 2** Based on [determinant of block matrix](https://en.wikipedia.org/wiki/Determinant#Block_matrices), we have\n",
    "    $$\n",
    "    \\begin{align}\n",
    "    \\det(\\Sigma)\n",
    "    &= \\det \\left ( \\begin{bmatrix} \\Sigma_{aa} & \\Sigma_{ab} \\\\ \\Sigma_{ba} & \\Sigma_{bb} \\end{bmatrix} \\right ) \\\\\n",
    "    &= \\det (\\Sigma_{aa}) \\det (\\Sigma_{bb}-\\Sigma_{ba}\\Sigma_{aa}^{-1}\\Sigma_{ab}) \\\\\n",
    "    &= \\det (\\Sigma_{aa}) \\det (\\Lambda_{bb}^{-1}) \n",
    "    \\end{align}\n",
    "    $$    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    ">    - The **joint PDF** is\n",
    "    \\begin{equation}\n",
    "    \\begin{split}\n",
    "    P(\\vec{x_a}, \\vec{x_b}) \\quad\n",
    "    &= \\frac{1}{(2 \\pi)^{(D_a+D_b)/2}} \\frac{1}{(\\det{\\Sigma})^\\frac12} \\exp \\left \\{ -\\frac12 \\begin{bmatrix}\n",
    "    (\\vec{x_a}-\\vec{\\mu_a})^T&(\\vec{x_b}-\\vec{\\mu_b})^T \n",
    "    \\end{bmatrix}\n",
    "    \\begin{bmatrix} \\Lambda_{aa} & \\Lambda_{ab} \\\\ \\Lambda_{ba} & \\Lambda_{bb} \\end{bmatrix}\n",
    "    \\begin{bmatrix}\n",
    "    \\vec{x_a}-\\vec{\\mu_a} \\\\ \n",
    "    \\vec{x_b}-\\vec{\\mu_b}\n",
    "    \\end{bmatrix} \\right \\} \\\\\n",
    "    & = \\frac{1}{(2\\pi)^{D_a/2}} \\frac{1}{\\det(\\Sigma_{aa})^\\frac12} \\exp \\left\\{-\\frac12 (\\vec{x_a}-\\vec{\\mu_a})^T \\Sigma_{aa}^{-1} (\\vec{x_a}-\\vec{\\mu_a}) \\right\\} \\cdot \\\\\n",
    "    & \\quad \\frac{1}{(2 \\pi)^{D_b/2}} \\frac{1}{\\det(\\Lambda_{bb}^{-1})^\\frac12} \\exp \\biggl \\{-\\frac12 \\biggl[ (\\vec{x_a}-\\vec{\\mu_a})^T(\\Lambda_{aa}-\\Sigma_{aa}^{-1})(\\vec{x_a}-\\vec{\\mu_a}) +\\\\\n",
    "    & \\quad (\\vec{x_b}-\\vec{\\mu_b})^T\\Lambda_{bb}(\\vec{x_b}-\\vec{\\mu_b})+ 2(\\vec{x_a}-\\vec{\\mu_a})^T \\Lambda_{ab}(\\vec{x_b}-\\vec{\\mu_b})) \\biggl] \\biggl\\} \\qquad \\text{(According to } \\textbf{Fact 2)}  \\\\\n",
    "    & = \\N(\\vec{x_a}|\\vec{\\mu_a}, \\Sigma_{aa}) \\cdot \\\\\n",
    "    & \\quad \\frac{1}{(2 \\pi)^{D_b/2}} \\frac{1}{\\det(\\Lambda_{bb}^{-1})^\\frac12} \\exp \\biggl \\{-\\frac12 \\biggl[ (\\vec{x_a}-\\vec{\\mu_a})^T\\Lambda_{ab}\\Lambda_{bb}^{-1}\\Lambda_{ba}(\\vec{x_a}-\\vec{\\mu_a}) + \\\\\n",
    "    & \\quad (\\vec{x_b}-\\vec{\\mu_b})^T\\Lambda_{bb}(\\vec{x_b}-\\vec{\\mu_b})+ 2(\\vec{x_a}-\\vec{\\mu_a})^T \\Lambda_{ab}(\\vec{x_b}-\\vec{\\mu_b})) \\biggl] \\biggl\\} \\qquad \\text{(According to } \\textbf{Fact 1)} \\\\\n",
    "    & = \\N(\\vec{x_a}|\\vec{\\mu_a}, \\Sigma_{aa})  \\cdot\\\\\n",
    "    & \\quad \\frac{1}{(2 \\pi)^{D_b/2}} \\frac{1}{\\det(\\Lambda_{bb}^{-1})^\\frac12} \\exp \\biggl \\{-\\frac12 \\biggl[ (\\vec{x_a}-\\vec{\\mu_a})^T\\Lambda_{ab}\\Lambda_{bb}^{-1}\\Lambda_{bb}\\Lambda_{bb}^{-1}\\Lambda_{ba}(\\vec{x_a}-\\vec{\\mu_a}) +\\\\\n",
    "    & \\quad (\\vec{x_b}-\\vec{\\mu_b})^T\\Lambda_{bb}(\\vec{x_b}-\\vec{\\mu_b})+ 2(\\vec{x_a}-\\vec{\\mu_a})^T \\Lambda_{ab}\\Lambda_{bb}^{-1}\\Lambda_{bb}(\\vec{x_b}-\\vec{\\mu_b})) \\biggl] \\biggl\\} \\\\\n",
    "    & = \\N(\\vec{x_a}|\\vec{\\mu_a}, \\Sigma_{aa}) \\cdot \\\\\n",
    "    &\\quad \\frac{1}{(2 \\pi)^{D_b/2}} \\frac{1}{\\det(\\Lambda_{bb}^{-1})^\\frac12} \\exp \\biggl \\{-\\frac12  [\\vec{x_b}-\\vec{\\mu_b}+\\Lambda_{bb}^{-1}\\Lambda_{ba}(\\vec{x_a}-\\vec{\\mu_a})]^T\\Lambda_{bb}[\\vec{x_b}-\\vec{\\mu_b}+\\Lambda_{bb}^{-1}\\Lambda_{ba}(\\vec{x_a}-\\vec{\\mu_a})] \\biggl\\} \\\\\n",
    "    & = \\boxed{ \\N(\\vec{x_a}|\\vec{\\mu_a}, \\Sigma_{aa}) \\N(\\vec{x_b}|\\vec{\\mu_b}-\\Lambda_{bb}^{-1}\\Lambda_{ba}(\\vec{x_a}-\\vec{\\mu_a}), \\Lambda_{bb}^{-1}) }\\\\\n",
    "    \\end{split}\n",
    "    \\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    ">    - So the **marginal PDF** is \n",
    "    $$\n",
    "    \\begin{equation}\n",
    "    \\begin{split}\n",
    "    P(\\vec{x_a}) \n",
    "    & = \\int P(\\vec{x_a}, \\vec{x_b}) \\d \\vec{x_b} \\\\\n",
    "    & = \\N(\\vec{x_a}|\\vec{\\mu_a}, \\Sigma_{aa}) \\int  \\N(\\vec{x_b}|\\vec{\\mu_b}-\\Lambda_{bb}^{-1}\\Lambda_{ba}(\\vec{x_a}-\\vec{\\mu_a}), \\Lambda_{bb}^{-1}) \\d \\vec{x_b} \\\\\n",
    "    & = \\N(\\vec{x_a}|\\vec{\\mu_a}, \\Sigma_{aa}) \\cdot 1 \\\\\n",
    "    & = \\boxed{ \\N(\\vec{x_a}|\\vec{\\mu_a}, \\Sigma_{aa}) }\n",
    "    \\end{split}\n",
    "    \\end{equation}\n",
    "    $$\n",
    "    \n",
    ">    - Similarly, we could prove $\\boxed{ P(\\vec{x_a}) = \\N(\\vec{x_b}|\\vec{\\mu_b}, \\Sigma_{bb}) }\\qed$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Partitioned Marginals:  Bivariate Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAAGqCAYAAABeetDLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n4/EsJV6gPB6Px7OU/P9zNy6dPD23LgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10859cc90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_mvn(2, 1, 4, 2, 1); # sigma_x_a, sigma_x_b, mu_x, mu_y, corr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Partitioned Conditionals\n",
    "\n",
    "- Given the setting of partition defined above, we have the **conditionals** \n",
    "    $$\n",
    "    \\begin{matrix}\n",
    "    \\boxed{\n",
    "    \\begin{align}\n",
    "    P(\\vec{x_b} | \\vec{x_a})\n",
    "    &= \\N(\\vec{x_b} | \\mu_{b|a}, \\Sigma_{b|a}) \\\\\n",
    "    \\Sigma_{b|a}\n",
    "    &= \\Sigma_{bb} - \\Sigma_{ba}\\Sigma_{aa}^{-1} \\Sigma_{ab} \\\\\n",
    "    \\mu_{b|a}\n",
    "    &= \\mu_b + \\Sigma_{ba} \\Sigma_{aa}^{-1} (\\vec{x_a} - \\mu_a)\n",
    "    \\end{align}\n",
    "    }\n",
    "    &\n",
    "    \\boxed{\n",
    "    \\begin{align}\n",
    "    P(\\vec{x_a} | \\vec{x_b})\n",
    "    &= \\N(\\vec{x_a} | \\mu_{a|b}, \\Sigma_{a|b}) \\\\\n",
    "    \\Sigma_{a|b}\n",
    "    &= \\Sigma_{aa} - \\Sigma_{ab}\\Sigma_{bb}^{-1} \\Sigma_{ba} \\\\\n",
    "    \\mu_{a|b}\n",
    "    &= \\mu_a + \\Sigma_{ab} \\Sigma_{bb}^{-1} (\\vec{x_b} - \\mu_b)\n",
    "    \\end{align}\n",
    "    }\n",
    "    \\end{matrix}\n",
    "    $$\n",
    "\n",
    "- Proof is in the **notes**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "> **Remark**\n",
    "> - The **conditional** distribution of $\\vec{x_a}|\\vec{x_b}$ means the distribution of $\\vec{x_a}$ given the value of $\\vec{x_b}$.\n",
    "\n",
    "> - For the following notes, we will use $\\vec{x_a}|\\vec{x_b}$ to denote \"**random variable $\\vec{x_a}$ given the value of $\\vec{x_b}$**\"\n",
    "\n",
    "> - For $\\vec{x_a}|\\vec{x_b}$, \n",
    "\n",
    ">    - Its **Mean** $\\mu_{a|b}$ is a linear function w.r.t. $\\vec{x_b}$.\n",
    "\n",
    ">    - Its **Covariance** $\\Sigma_{a|b}$ is constant no matter what $\\vec{x_b}$ is.\n",
    "\n",
    "> - **Proof** for partitioned conditionals\n",
    "\n",
    ">     - From previous **Remark**, we already showed \n",
    "$$\n",
    "    \\begin{align}\n",
    "    P(\\vec{x_a}, \\vec{x_b}) &= \\N(\\vec{x_a}|\\vec{\\mu_a}, \\Sigma_{aa}) \\N(\\vec{x_b}|\\vec{\\mu_b}-\\Lambda_{bb}^{-1}\\Lambda_{ba}(\\vec{x_a}-\\vec{\\mu_a}), \\Lambda_{bb}^{-1}) \\\\\n",
    "    P(\\vec{x_a}) &= \\N(\\vec{x_a}|\\vec{\\mu_a}, \\Sigma_{aa})\n",
    "    \\end{align}\n",
    "    $$\n",
    "    So the conditional is\n",
    "    $$\n",
    "    P(\\vec{x_b}|\\vec{x_a}) = \\frac{P(\\vec{x_a}, \\vec{x_b})}{P(\\vec{x_a})} = \\N(\\vec{x_b}|\\vec{\\mu_b}-\\Lambda_{bb}^{-1}\\Lambda_{ba}(\\vec{x_a}-\\vec{\\mu_a}), \\Lambda_{bb}^{-1})\n",
    "    $$\n",
    "    Based on results from **Fact 1** in previous **Remark**, we have\n",
    "    $$\n",
    "    P(\\vec{x_b}|\\vec{x_a}) = \\N(\\vec{x_b}|\\underbrace{\\mu_b + \\Sigma_{ba}\\Sigma_{aa}^{-1}(\\vec{x_a}-\\mu_a)}_{\\mu_{b|a}}, \\underbrace{\\Sigma_{bb}-\\Sigma_{ba}\\Sigma_{aa}^{-1}\\Sigma_{ab}}_{\\Sigma_{b|a}})\n",
    "    $$\n",
    "    Similarly we could prove $P(\\vec{x_a}|\\vec{x_b})$ case. $\\qed$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "- Illustration of conditionals\n",
    "<center> <img src=\"images/partitioned-conditionals.png\"  style=\"width:500px;height:240px;\"> </center>\n",
    "- The conditional is obtained by \"slicing\" the joint PDF.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Linear Gaussian Systems:  Model\n",
    "- **Just then** we have just showed if we partition a multivariate Gaussian into two vectors\n",
    "    $$\n",
    "    \\begin{bmatrix}  \\vec{x_a} \\\\ \\vec{x_b} \\end{bmatrix}\n",
    "    \\sim\n",
    "    \\N \\left(\n",
    "    \\begin{bmatrix} \\vec{\\mu_a} \\\\ \\vec{\\mu_b} \\end{bmatrix},\n",
    "    \\begin{bmatrix}\n",
    "    \\Sigma_{aa} & \\Sigma_{ab} \\\\  \\Sigma_{ba} & \\Sigma_{bb}\n",
    "    \\end{bmatrix}\n",
    "    \\right)\n",
    "    $$\n",
    "    we have the following conditional with mean a **linear** function w.r.t. $\\vec{x_b}$\n",
    "    $$\n",
    "    P(\\vec{x_a} | \\vec{x_b}) = \\N(\\vec{x_a} | \\mu_{a|b}, \\Sigma_{a|b})\n",
    "    \\quad \\mu_{a|b} = \\mu_a + \\Sigma_{ab} \\Sigma_{bb}^{-1} (\\vec{x_b} - \\mu_b)\n",
    "    \\quad \\Sigma_{a|b} = \\Sigma_{aa} - \\Sigma_{ab}\\Sigma_{bb}^{-1} \\Sigma_{ba} \n",
    "    $$    \n",
    "\n",
    "- **Now** let's consider a **different** but **similar** setting:\n",
    "    - We have a **Gaussian** $\\vec{x} \\in \\R^{D_X}$ and **some** $\\vec{y} \\in \\R^{D_Y}$ of which\n",
    "    $$\n",
    "    \\vec{x} \\sim \\N(\\mu_x, \\Sigma_x) \\quad (\\mu_\\vx \\text{ and } \\Sigma_\\vx \\text{ are } \\textbf{known} )\n",
    "    $$\n",
    "    And the conditional relation between $\\vec{x}$ and $\\vec{y}$ is\n",
    "    $$\n",
    "    \\vec{y}|\\vec{x} \\sim \\N(A\\vec{x}+\\vb, \\Sigma_{\\vy|\\vx}) \\quad (A, b \\text{ and } \\Sigma_{\\vy|\\vx} \\text{ are } \\textbf{known} )\n",
    "    $$\n",
    "    which says $\\vy|\\vx$ is also a Gaussian with mean $\\mu_{\\vy|\\vx}$ a **linear** function of $\\vx$\n",
    "\n",
    "- **Then**, what is the distribution of $\\vy$ and what is the distribution of $\\vx|\\vy$?\n",
    "    - Are they also **Gaussian**? \n",
    "    - If so, what are the mean and covariance?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Linear Gaussian Systems:  Bayes' Theorem\n",
    "\n",
    "- Actually, given\n",
    "    $$\n",
    "    \\vec{x} \\sim \\N(\\mu_\\vx, \\Sigma_\\vx) \\quad \\text{and} \\quad \\vec{y}|\\vec{x} \\sim \\N(A\\vec{x}+\\vb, \\Sigma_{\\vy|\\vx})\n",
    "    $$\n",
    "    we could show \n",
    "    $$\n",
    "    \\boxed{\\vy \\sim \\mathcal{N}( A\\mu_\\vx + \\vb, \\Sigma_{\\vy|\\vx} + A\\Sigma_\\vx A^T)}\n",
    "    $$\n",
    "    and\n",
    "    $$\n",
    "    \\boxed{\\vx|\\vy \\sim \\mathcal{N}( \\mu_{\\vx|\\vy}, \\Sigma_{\\vy|\\vx})}\n",
    "    $$\n",
    "    of which\n",
    "    $$\n",
    "    \\begin{align}\n",
    "    \\Sigma_{\\vx|\\vy} &= (\\Sigma_\\vx^{-1} + A^T \\Sigma_{\\vy|\\vx}^{-1} A)^{-1} \\\\\n",
    "    \\mu_{\\vx|\\vy} &= \\Sigma_{\\vx|\\vy} \\left[\n",
    "    A^T \\Sigma_{\\vy|\\vx}^{-1} (\\vy-b) + \\Sigma_\\vx^{-1} \\mu_\\vx \n",
    "    \\right]\n",
    "    \\end{align}\n",
    "    $$\n",
    "\n",
    "- Proof is in the **notes**\n",
    "\n",
    "- This theorem will play a **key role** throughout this lecture."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "> **Remark**\n",
    "\n",
    "> - **Proof for $\\vy$ (*Less* rigorous one)**\n",
    "\n",
    ">    - Let's assume (less rigorous because here we directly assume $\\vy$ to have Gaussian distribution)\n",
    "    $$\\vy \\sim \\N(\\mu_\\vy, \\Sigma_\\vy)$$\n",
    "    So based on conditional of partitioned Gaussion, we have\n",
    "    $$\n",
    "    \\vy|\\vx \\sim \\N(\\mu_\\vy + \\Sigma_{\\vy\\vx}\\Sigma_{\\vx}^{-1}(\\vx-\\mu_\\vx), \\Sigma_\\vy-\\Sigma_{\\vy\\vx}\\Sigma_{\\vx}^{-1}\\Sigma_{\\vx\\vy})\n",
    "    $$\n",
    "    Since we have known $\\vec{y}|\\vec{x} \\sim \\N(A\\vec{x}+\\vb, \\Sigma_{\\vy|\\vx})$, we could have the following equations\n",
    "    $$\n",
    "    \\left\\{\\begin{array}{l}    \\Sigma_{\\vy\\vx}\\Sigma_\\vx^{-1} = A   \\\\    \\mu_\\vy - \\Sigma_{\\vy\\vx} \\Sigma_\\vx^{-1}\\mu_\\vx = \\vb   \\\\    \\Sigma_\\vy-\\Sigma_{\\vy\\vx}\\Sigma_\\vx^{-1}\\Sigma_{\\vx\\vy} = \\Sigma_{\\vy|\\vx}    \\end{array}\\right.\n",
    "    \\Rightarrow\n",
    "    \\left\\{\\begin{array}{l}   \\Sigma_{\\vy\\vx}=A\\Sigma_\\vx,\\ \\Sigma_{\\vx\\vy}=\\Sigma_\\vx A^T    \\\\    \\mu_\\vy=A\\mu_\\vx+\\vb    \\\\    \\Sigma_\\vy=\\Sigma_{\\vy|\\vx}+A\\Sigma_\\vx A^T    \\end{array}\\right.\n",
    "    \\Rightarrow\n",
    "    \\vy \\sim \\N(A\\mu_\\vx + \\vb, \\Sigma_{\\vy|\\vx} + A\\Sigma_\\vx A^T) \\qed\n",
    "    $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "> - **Proof for $\\vx|\\vy$**\n",
    "\n",
    ">    - We already have\n",
    "    $$\n",
    "    \\left\\{\\begin{array}{l}    \\vec{x} \\sim \\N(\\mu_\\vx, \\Sigma_\\vx)   \\\\    \\vy \\sim \\mathcal{N}( \\underbrace{A\\mu_\\vx + \\vb}_{\\mu_\\vy}, \\underbrace{\\Sigma_{\\vy|\\vx} + A\\Sigma_\\vx A^T)}_{\\Sigma_\\vy}   \\\\    \\Sigma_{\\vy\\vx}=A\\Sigma_\\vx,\\ \\Sigma_{\\vx\\vy}=\\Sigma_\\vx A^T     \\end{array}\\right.\n",
    "    $$\n",
    "    According to conditional of partitioned Gaussian, we know $\\vx|\\vy$ has Gaussian distribution, so we could assume\n",
    "    $$\\vx|\\vy \\sim \\N(\\mu_{\\vx|\\vy}, \\Sigma_{\\vx|\\vy})$$\n",
    "    Applying the result of conditional of partitioned Gaussian, we have covariance:\n",
    "    $$\n",
    "    \\begin{align}\n",
    "    \\Sigma_{\\vx|\\vy} \n",
    "    &= \\Sigma_\\vx - \\Sigma_{\\vx\\vy} \\Sigma_{\\vy}^{-1} \\Sigma_{\\vy\\vx} \\\\\n",
    "    &= \\Sigma_\\vx - \\Sigma_{\\vx}A^T (\\Sigma_{\\vy|\\vx}+A\\Sigma_{\\vx}A^T)^{-1} A \\Sigma_{\\vx} \\\\\n",
    "    &= \\boxed{(\\Sigma_\\vx^{-1} + A^T \\Sigma_{\\vy|\\vx}^{-1} A)^{-1}}\n",
    "    \\end{align}\n",
    "    $$\n",
    "    of which the last equation is based on matrix inversion lemma. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - **Proof for $\\vx|\\vy$**\n",
    ">    - And we have mean:\n",
    "    $$\n",
    "    \\begin{align}\n",
    "    \\mu_{\\vx|\\vy}\n",
    "    &= \\mu_\\vx + \\Sigma_{\\vx\\vy}\\Sigma_{\\vy}^{-1}(\\vy-\\mu_{\\vy}) \\\\\n",
    "    &= \\mu_\\vx + \\Sigma_{\\vx\\vy} \\Sigma_{\\vy}^{-1} (\\vy-A\\mu_\\vx-\\vb) \\\\\n",
    "    &= \\Sigma_{\\vx\\vy} \\Sigma_{\\vy}^{-1} (\\vy-\\vb) + (I-\\Sigma_{\\vx\\vy} \\Sigma_{\\vy}^{-1}A)\\mu_\\vx\n",
    "    \\end{align}\n",
    "    $$\n",
    "    of which\n",
    "    $$\n",
    "    \\begin{align}\n",
    "    \\Sigma_{\\vx\\vy} \\Sigma_{\\vy}^{-1}\n",
    "    &= \\Sigma_\\vx A^T (\\Sigma_{\\vy|\\vx} + A \\Sigma_\\vx A^T)^{-1} \\\\\n",
    "    &= \\Sigma_{\\vx|\\vy} [ \\Sigma_{\\vx|\\vy}^{-1} \\Sigma_\\vx A^T (\\Sigma_{\\vy|\\vx} + A \\Sigma_\\vx A^T)^{-1} ] \\\\\n",
    "    &= \\Sigma_{\\vx|\\vy} [(\\Sigma_\\vx+A^T \\Sigma_{\\vy|\\vx}^{-1} A) \\Sigma_\\vx A^T (\\Sigma_{\\vy|\\vx} + A \\Sigma_\\vx A^T)^{-1} ] \\\\\n",
    "    &= \\Sigma_{\\vx|\\vy} [ (A^T + A^T \\Sigma_{\\vy|\\vx}^{-1} A \\Sigma_\\vx A^T) (\\Sigma_{\\vy|\\vx} + A \\Sigma_\\vx A^T)^{-1} ] \\\\\n",
    "    &= \\Sigma_{\\vx|\\vy} A^T [ (I + \\Sigma_{\\vy|\\vx}^{-1} A \\Sigma_\\vx A^T) (\\Sigma_{\\vy|\\vx} + A \\Sigma_\\vx A^T)^{-1} ] \\\\\n",
    "    &= \\Sigma_{\\vx|\\vy} A^T \\Sigma_{\\vy|\\vx}^{-1} [ (\\Sigma_{\\vy|\\vx} +  A \\Sigma_\\vx A^T) (\\Sigma_{\\vy|\\vx} + A \\Sigma_\\vx A^T)^{-1} ] \\\\\n",
    "    &= \\Sigma_{\\vx|\\vy} A^T \\Sigma_{\\vy|\\vx}^{-1} \\\\\n",
    "    \\end{align}\n",
    "    $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - **Proof for $\\vx|\\vy$**\n",
    "    $$\n",
    "    \\begin{align}\n",
    "    I-\\Sigma_{\\vx\\vy} \\Sigma_{\\vy}^{-1}A \n",
    "    &= I-\\Sigma_{\\vx|\\vy} A^T \\Sigma_{\\vy|\\vx}^{-1} A \\\\\n",
    "    &= \\Sigma_{\\vx|\\vy} (\\Sigma_{\\vx|\\vy}^{-1} - A^T \\Sigma_{\\vy|\\vx}^{-1} A)\\\\\n",
    "    &= \\Sigma_{\\vx|\\vy} (\\Sigma_{\\vx}^{-1} + A^T \\Sigma_{\\vy|\\vx}^{-1} A - A^T \\Sigma_{\\vy|\\vx}^{-1} A)\\\\\n",
    "    &= \\Sigma_{\\vx|\\vy} \\Sigma_{\\vx}^{-1}\n",
    "    \\end{align}\n",
    "    $$\n",
    "    Plug this back to the mean,\n",
    "    $$\n",
    "    \\begin{align}\n",
    "    \\mu_{\\vx|\\vy}\n",
    "    &= \\Sigma_{\\vx|\\vy} A^T \\Sigma_{\\vy|\\vx}^{-1} (\\vy - \\vb) + \\Sigma_{\\vx|\\vy} \\Sigma_{\\vx}^{-1} \\mu_\\vx \\\\\n",
    "    &= \\boxed{\\Sigma_{\\vx|\\vy} [ A^T \\Sigma_{\\vy|\\vx}^{-1} (\\vy - \\vb) + \\Sigma_{\\vx}^{-1} \\mu_\\vx]} \\qed\n",
    "    \\end{align}\n",
    "    $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Bayesian Linear Regression \n",
    "\n",
    "> Taken from **[PRML]** §3.3, **[MLAPP]** §7.6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Review:  Regression\n",
    "- In last lecture, we have the model for single data point $(\\vec{x}, t)$\n",
    "    $$\n",
    "    \\begin{gather}\n",
    "    t = \\vec{w}^T \\phi(\\vec{x}) + \\epsilon \\\\ \n",
    "    \\epsilon \\sim \\mathcal{N}(0, \\beta^{-1}) \\\\\n",
    "    t\\, | \\,\\vx,\\vw   \\sim \\mathcal{N}(\\vec{w}^T \\phi(\\vec{x}), \\beta^{-1})\n",
    "    \\end{gather}\n",
    "    $$\n",
    "\n",
    "- So for inputs $\\mathcal{X}=(\\vec{x}_1, \\dots, \\vec{x}_n)$ and target values $\\vec{t}=(t_1,\\dots,t_n)$, we have\n",
    "    $$\n",
    "    \\begin{gather}\n",
    "    \\vt\\, | \\,\\mathcal{X}, \\vw \\sim \\N(\\Phi \\vw, \\beta^{-1}I)\n",
    "    \\end{gather}\n",
    "    $$\n",
    "    \n",
    "- Recall in last lecture, if we have **prior** $\\vec{w} \\sim \\mathcal{N}(\\vec{0}, \\alpha^{-1}I)$, the **MAP Estimate** of $\\vw$ corresponds to solution to **ridge regression** (least squares with $\\ell^2$ regularization) $$\\vec{w}_{MAP} = (\\Phi^T \\Phi + \\frac{\\alpha}{\\beta} I)^{-1} \\Phi^T \\vec{t}$$\n",
    "\n",
    "- Next, we will see what $\\vw$'s **posterior** $P(\\vw \\, | \\, \\mathcal{X}, \\vt)$ is with more general prior.\n",
    "\n",
    "- Note that $\\vec{w}_{MAP}$ is just a single point estimate of **posterior** $P(\\vw \\, | \\, \\mathcal{X}, \\vt)$. More about this will come later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "> **Remark**\n",
    "> - Recall **design matrix** $\\Phi$ is\n",
    "    $$\n",
    "    \\Phi = \\begin{bmatrix}\n",
    "    \\phi(\\vec{x}_1)^T\\\\ \n",
    "    \\phi(\\vec{x}_2)^T\\\\ \n",
    "    \\vdots\\\\\n",
    "    \\phi(\\vec{x}_N)^T\n",
    "    \\end{bmatrix}\n",
    "    = \\begin{bmatrix}\n",
    "    \\phi_0(\\vec{x}_1) & \\phi_1(\\vec{x}_1) & \\cdots & \\phi_{M-1}(\\vec{x}_1) \\\\\n",
    "    \\phi_0(\\vec{x}_2) & \\phi_1(\\vec{x}_2) & \\cdots & \\phi_{M-1}(\\vec{x}_2) \\\\\n",
    "    \\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "    \\phi_0(\\vec{x}_N) & \\phi_1(\\vec{x}_N) & \\cdots & \\phi_{M-1}(\\vec{x}_N) \\\\\n",
    "    \\end{bmatrix}\n",
    "    $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Bayesian Linear Regression\n",
    "- We have **prior** for coefficients $\\vw$\n",
    "    $$\n",
    "    P(\\vw) = \\N(\\vw \\, | \\, \\vec{m}_0, S_0)\n",
    "    $$\n",
    "\n",
    "- And from last slide, we have **likelihood**\n",
    "    $$\n",
    "    P(\\vt \\, | \\, \\vw, \\mathcal{X}) = \\N(\\vt \\, | \\, \\Phi \\vw, \\beta^{-1}I)\n",
    "    $$\n",
    "\n",
    "- **Bayesian Linear Regression** computes the full **posterior** over the weights (prior),\n",
    "    $$\n",
    "    \\begin{align}\n",
    "    P(\\vw \\, | \\, \\vt, \\mathcal{X})\n",
    "    & = \\frac{P(\\vt \\,|\\, \\vw, \\mathcal{X}) P(\\vw \\,|\\, \\mathcal{X})}{P(\\vt \\,|\\, \\mathcal{X})} \\\\\n",
    "    &\\propto P(\\vt \\,|\\, \\vw, \\mathcal{X}) P(\\vw \\,|\\, \\mathcal{X}) \\\\\n",
    "    &\\propto \\underbrace{P(\\vt \\, | \\, \\vw, \\mathcal{X})}_{\\text{Likelihood}} \\underbrace{P(\\vw)}_{\\text{Prior}} \\qquad \\text{(Drop } \\mathcal{X} \\text{ because of independence)}\\\\\n",
    "    &\\propto \\N(\\vt \\, | \\, \\Phi \\vw, \\beta^{-1}I) \\N(\\vw \\, | \\, \\vec{m}_0, S_0) \\\\\n",
    "    & = \\mathcal{N}(\\vw \\, | \\, \\vec{m}_N, S_N) \\qquad \\text{(Can be obtained from some normalization)}\n",
    "    \\end{align}\n",
    "    $$\n",
    "    where\n",
    "    $$\n",
    "    \\boxed{S_N = (S_0^{-1} + \\beta \\Phi^{T} \\Phi)^{-1} \\qquad \\vec{m}_N = S_N(\\beta \\Phi^T \\vt + S_0^{-1} \\vec{m}_0)}\n",
    "    $$\n",
    "    \n",
    "- We will derive this using results we just derived in Bayes' Theorem for Linear Gaussian"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "> **Remark**\n",
    "\n",
    "> - Generally, we should follow $$\\text{Posterior} = \\text{Likelihood} \\times \\text{Prior}$$ to compute the posterior. But since we have the results from Bayes'Theorem for Linear Gaussian, we will use directly.\n",
    "\n",
    "> - **Posterior** $P(\\vw \\, | \\, \\vt, \\mathcal{X})$ tells us our prior belief in $\\vw$ with **mean** $\\vec{m}_0$ and **covariance** $S_0$ has been updated to **mean** $\\vec{m}_N$ and **covariance** $S_N$.\n",
    "\n",
    "> - We will show this change in some plots later.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Bayesian Linear Regression: Derivation\n",
    "- Following the results in Bayes' Theorem for Linear Gaussian, we have\n",
    "    $$\n",
    "    \\boxed{\n",
    "    \\begin{align}\n",
    "    & \\text{Bayes' Theorem of Linear Gaussian} \\\\\n",
    "    \\vec{x} & \\sim \\N(\\mu_\\vx, \\Sigma_\\vx) \\\\\n",
    "    \\vec{y}|\\vec{x} & \\sim \\N(A\\vec{x}+\\vb, \\Sigma_{\\vy|\\vx}) \\\\\n",
    "    & \\Downarrow \\\\\n",
    "    \\vx|\\vy &\\sim \\mathcal{N}( \\mu_{\\vx|\\vy}, \\Sigma_{\\vy|\\vx}) \\\\\n",
    "    \\Sigma_{\\vx|\\vy} &= (\\Sigma_\\vx^{-1} + A^T \\Sigma_{\\vy|\\vx}^{-1} A)^{-1} \\\\\n",
    "    \\mu_{\\vx|\\vy} &= \\Sigma_{\\vx|\\vy} \\left[A^T \\Sigma_{\\vy|\\vx}^{-1} (\\vy-b) + \\Sigma_\\vx^{-1} \\mu_\\vx \\right] \\end{align}\n",
    "    }\n",
    "    \\Rightarrow\n",
    "    \\boxed{\n",
    "    \\begin{align}\n",
    "    & \\text{Posterior of } \\vw\\\\\n",
    "    \\vw | \\mathcal{X} & \\sim \\N(\\vec{m}_0, S_0) \\\\\n",
    "    \\vt|\\vw , \\mathcal{X} & \\sim \\N(\\Phi \\vw, \\beta^{-1}I) \\\\\n",
    "    & \\Downarrow \\\\\n",
    "    \\vw|\\vt , \\mathcal{X} &\\sim \\N(\\vec{m}_N, S_N) \\\\\n",
    "    S_N &= (S_0^{-1} + \\beta \\Phi^{T} \\Phi)^{-1} \\\\\n",
    "    \\vec{m}_N &= S_N(\\beta \\Phi^T \\vt + S_0^{-1} \\vec{m}_0 )\n",
    "    \\end{align}\n",
    "    }\n",
    "    $$    \n",
    "\n",
    "- Done!\n",
    "\n",
    "- Don't get confused by $\\mathcal{X}$ in the condition position. We are free to drop it without any impact.\n",
    "\n",
    "- Think like a Bayesian. Sometimes we usually drop some priors like \"Coin is fair\" in $P( \\text{Head} \\,|\\, \\text{Coin is fair})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### BLR:  Simplifying the Prior\n",
    "\n",
    "- Assume $\\vec{m}_0 = 0$ and $S_0 = \\alpha^{-1}I$ (like what we did in ridge regression), we have\n",
    "    $$\n",
    "    P(\\vw \\, | \\, \\vt, \\mathcal{X}) = \\mathcal{N}(\\vw \\, | \\, \\vec{m}_N, S_N)\n",
    "    $$\n",
    "    where\n",
    "    $$\n",
    "    S_N =  (\\alpha I + \\beta \\Phi^T \\Phi)^{-1} \\\\\n",
    "    \\vec{m}_N = \\beta S_N \\Phi^T \\vt = (\\Phi^T \\Phi + \\frac{\\alpha}{\\beta} I)^{-1} \\Phi^T \\vt\n",
    "    $$\n",
    "\n",
    "- Note that the **posterior mean** $\\vec{m}_N$ is the **MAP estimate** of $\\vw$. \n",
    "\n",
    "- This makes sense because **posterior mean** is exactly the point that maximizes the posterior P(\\vw|\\vt, \\mathcal{X}, \\beta).\n",
    "\n",
    "- **Posterior Covariance** $S_N$ tells us how confident we are in our prediction $\\vw_{MAP}$ because it tells us how far $\\vw$ are spread out from its mean $\\vw_{MAP}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Sequential Bayesian Learning\n",
    "\n",
    "- Sometimes, our data is *streaming*, and we want to learn $\\vw$ in a online fashion.\n",
    "\n",
    "- **Note:** The posterior $P(\\vw\\, | \\,\\vt, \\mathcal{X})$ and prior $P(\\vw)$ are both Gaussians. \n",
    "    - We can use the posterior for one set of observations as a prior for the next set of observations.\n",
    "    - And following exactly the same procedures as above, we will get a new posterior .\n",
    "    - Starting from a fixed prior, sequentially update our beliefs as new data arrives.\n",
    "    \n",
    "- Here are the details\n",
    "    - **Initialize** $\\vec{m}_0$ and $S_0$ of $\\N(\\vw \\, | \\, m_0, S_0)$\n",
    "    - **Repeat** when the $ith$ obseravation $\\{\\mathcal{X}_i, \\vt_i \\}$ arrives\n",
    "        - $S_i = (S_{i-1}^{-1} + \\beta \\Phi_{\\mathcal{X}_i}^{T} \\Phi_{\\mathcal{X}_i})^{-1}$\n",
    "        - $\\vec{m}_i = S_i(\\beta \\Phi_{\\mathcal{X}_i}^T \\vt_i + S_{i-1}^{-1} \\vec{m}_{i-1})$\n",
    "    - **End**\n",
    "    \n",
    "- This is **Bayesian Updating**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Sequential Bayesian Learning: Example\n",
    "\n",
    "- Assume observation $y$ is generated by\n",
    "    $$y = w_1 x + w_0 + \\epsilon$$\n",
    "    of which\n",
    "    $$w_1 = 0.5,\\ w_0 = -0.3,\\ \\epsilon \\sim \\N(0, \\beta^{-1})$$\n",
    "    (We use both $y$ and $t$ to denote observations)\n",
    "- We want to learn the coefficients $w_1$ and $w_0$ using sequential Bayesian learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Sequential Bayesian Learning: Example—No Data Comes Yet\n",
    "\n",
    "<center> <img src=\"images/sbl1.png\"  style=\"width:571px;height:167px;\"> </center>\n",
    "\n",
    "- **First Plot**—Nothing\n",
    "- **Second Plot**—Prior $P(\\vw) = \\N(\\vw \\, | \\, \\vec{m}_0, S_0)$\n",
    "- **Third Plot**—Sample lines of $y = w_1x+w_0$\n",
    "    - We draw 6 samples $\\vw$ based on distribution $\\N(\\vw \\, | \\, \\vec{m}_0, S_0)$ and plot the lines $y = w_1x+w_0$\n",
    "    - We could see they are highly scattered and far from the true line $y = 0.5x-0.3$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Sequential Bayesian Learning: Example—First Observation Arrives\n",
    "- First observation $\\{y_1, x_1\\}$ (has been marked with blue circle in third plot)\n",
    "    <center> <img src=\"images/sbl2.png\"  style=\"width:571px;height:167px;;\"> </center>\n",
    "\n",
    "- **First Plot**—Likelihood $P(y = y_1 \\, | \\, \\vw, x_1) = P(y=y_1 \\, | \\, w_1x_1+w_0, \\beta^{-1})$\n",
    "    - Shows the probability of observing $y_1$ from distribution $\\N(\\ w_1x_1+w_0, \\beta^{-1})$ given different values of $\\vw$.\n",
    "    - $\\vw$ from *redder* region are more likely to produce $y_1$ given $x_1$\n",
    "    - True $\\vw=[-0.3, 0.5]$ (marked with white cross) falls in the orange zone.\n",
    "\n",
    "- **Second Plot**—Posterior $P(\\vw \\, | \\, y_1, x_1) = \\N(\\vw \\, | \\, m_1, S_1)$\n",
    "    - Computed from prior $\\N(\\vw | m_0, S_0)$ and the first observation\n",
    "    - Variance is smaller compared with our prior belief\n",
    "    - The mean is still far from true $\\vw=[-0.3, 0.5]$\n",
    "\n",
    "- **Third Plot**—Sample lines of $y = w_1x + w_0$ where $\\vw$ is drawn from $\\N(\\vw \\, | \\, m_1, S_1)$\n",
    "    - Still scattered and far from true line $y = 0.5x-0.3$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Sequential Bayesian Learning: Example—Second Observation Arrives\n",
    "- Second observation $\\{y_2, x_2\\}$ (has been marked with blue circle in the left corner third plot)\n",
    "    <center> <img src=\"images/sbl3.png\"  style=\"width:571px;height:167px;;\"> </center>\n",
    "\n",
    "- **First Plot**—Likelihood $P(y=y_2 \\, | \\, \\vw, x_2) = P(y=y_2 \\, | \\, w_1x_2+w_0, \\beta^{-1})$\n",
    "    - True $\\vw=[-0.3, 0.5]$ (marked with white cross) still falls in the orange zone.\n",
    "\n",
    "- **Second Plot**—Posterior $P(\\vw \\, | \\, y_1, x_1, y_2, x_2) = \\N(\\vw \\, | \\, m_2, S_2)$\n",
    "    - Computed from posterior $\\N(\\vw \\, | \\, m_1, S_1)$ and the second observation\n",
    "    - Variance is even smaller\n",
    "    - The mean has moved much closer to $\\vw=[-0.3, 0.5]$\n",
    "\n",
    "- **Third Plot**—Sample lines of $y = w_1x + w_0$ where $\\vw$ is drawn from $\\N(\\vw \\, | \\, m_2, S_2)$\n",
    "    - Less scattered and slope is closer to $y = 0.5x-0.3$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Sequential Bayesian Learning: Example—More Data Arrives\n",
    "- More observations $\\{y_i, x_i\\}_{i=3}^N$ arrive (have been marked with blue circle third plot)\n",
    "    <center> <img src=\"images/sbl4.png\"  style=\"width:571px;height:167px;;\"> </center>\n",
    "\n",
    "- **First Plot**—Likelihood $P(y = y_N \\, | \\, \\vw, x_N) = P(y=y_N \\, | \\, w_1x_N+w_0, \\beta^{-1})$\n",
    "    - Although for different $\\{y_i, x_i\\}$, the likelihood plots have different slope, true $\\vw=[-0.3, 0.5]$ always falls in the highly likely region.\n",
    "    \n",
    "- **Second Plot**—Posterior $P(\\vw \\, | \\, \\{y_i, x_i\\}_{i=1}^N ) = \\N(\\vw \\, | \\,  m_N, S_N)$\n",
    "    - Computed from posterior $\\N(\\vw \\, | \\,  m_{N-1}, S_{N-1})$ and the second observation\n",
    "    - The iridescent ring almost shrinks to a *point* locates at $[-0.3, 0.5]$\n",
    "    - This indicates the variance is really small and mean is really close to true value.\n",
    "\n",
    "- **Third Plot**—Sample lines of $y = w_1x + w_0$ where $\\vw$ is drawn from $\\N(\\vw \\, | \\, m_N, S_N)$\n",
    "    - The lines almost converge to true $y = 0.5x-0.3$\n",
    "    \n",
    "- For details of these plots, please refer to **[PRML]**-P154."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Predictive Distribution\n",
    "- Recall our ultimate goal in linear regression is to predict $t$ for new data $\\vx$\n",
    "\n",
    "    - We could take the mean of posterior $\\vec{m}_N$ as the estimate of $\\vw$ and get a prediction $$t = \\vec{m}_N^T \\phi(\\vx)$$\n",
    "\n",
    "    - **But**, this could be a waste of the posterior of $\\vw$. We want to know more about prediction $t$.\n",
    "\n",
    "    - Actually, we could obtain distribution of $t$ based on the full posterior of $\\vw$\n",
    "\n",
    "- Let $\\mathcal{D} = \\{ (t_i, \\vx_i) \\}_{i=1}^N$ denote the training data. Then the **predictive distributinon** for some **new data** $\\vx$ is\n",
    "    $$\n",
    "    \\begin{align}\n",
    "    P(t \\, | \\, \\vx, \\mathcal{D})\n",
    "    &= \\int_\\vw P(t, \\vw \\, | \\, \\vx, \\mathcal{D}) \\, \\d \\vw \\\\\n",
    "    &= \\int_\\vw  P(t \\, | \\, \\vw, \\vx, \\mathcal{D})  P(\\vw \\, | \\, \\vx, \\mathcal{D})  \\, \\d \\vw \\\\\n",
    "    &= \\int_\\vw  P(t \\, | \\, \\vw, \\vx)  P(\\vw \\, | \\, \\mathcal{D}) \\, \\d \\vw \\\\\n",
    "    &= \\int_\\vw \\mathcal{N}(t \\, | \\, \\vw^T\\phi(\\vx), \\beta^{-1})\\mathcal{N}(\\vw \\, | \\, \\vec{m}_N, S_N)  \\, \\d \\vw\n",
    "    \\end{align}\n",
    "    $$\n",
    "    The third quality holds because $t$ is independent of $\\mathcal{D}$ and $\\vw$ is independent of $\\vx$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Predictive Distribution: Derivation\n",
    "\n",
    "- We don't have to take the pains to do integration!\n",
    "- The results we derived in Bayes' theorem for linear Gaussian will save us!\n",
    "    $$\n",
    "    \\boxed{\n",
    "    \\begin{align}\n",
    "    & \\text{Previous Results} \\\\\n",
    "    \\vec{x} & \\sim \\N(\\mu_\\vx, \\Sigma_\\vx) \\\\\n",
    "    \\vec{y}|\\vec{x} & \\sim \\N(A\\vec{x}+\\vb, \\Sigma_{\\vy|\\vx}) \\\\\n",
    "    & \\Downarrow \\\\\n",
    "    \\vy &\\sim \\N(A \\mu_\\vx + b, \\Sigma_{\\vy|\\vx} + A \\Sigma_\\vx A^T) \n",
    "    \\end{align}\n",
    "    }\n",
    "    \\Rightarrow\n",
    "    \\boxed{\n",
    "    \\begin{align}\n",
    "    & \\text{Prediction of } \\vw\\\\\n",
    "    \\vw | \\vx, \\mathcal{D}  & \\sim \\N(\\vec{m}_N, S_N) \\\\\n",
    "    t|\\vw, \\vx, \\mathcal{D} & \\sim \\N(\\phi^T \\vw, \\beta^{-1}) \\\\\n",
    "    & \\Downarrow \\\\\n",
    "    t \\, | \\, \\vx, \\mathcal{D} & \\sim \\N(\\, \\phi(\\vx)^T \\vec{m}_n \\,, \\,{\\beta}^{-1} + \\phi(\\vx)^T S_N \\phi(\\vx) \\,)\n",
    "    \\end{align}\n",
    "    }\n",
    "    $$\n",
    "- So, we have \n",
    "    $$\n",
    "    \\boxed{P(t \\, | \\, \\vx, \\mathcal{D}) = \\N(t \\, | \\, \\phi(\\vx)^T \\vec{m}_n \\,, \\,{\\beta}^{-1} + \\phi(\\vx)^T S_N \\phi(\\vx) \\,)}\n",
    "    $$\n",
    "- Done!    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Predictive Distribution: Derivation\n",
    "\n",
    "- We don't have to take the pains to do integration!\n",
    "- The results we derived in Bayes' theorem for linear Gaussian will save us!\n",
    "    $$\n",
    "    \\boxed{\n",
    "    \\begin{align}\n",
    "    & \\text{Previous Results} \\\\\n",
    "    \\vec{x} & \\sim \\N(\\mu_\\vx, \\Sigma_\\vx) \\\\\n",
    "    \\vec{y}|\\vec{x} & \\sim \\N(A\\vec{x}+\\vb, \\Sigma_{\\vy|\\vx}) \\\\\n",
    "    & \\Downarrow \\\\\n",
    "    \\vy &\\sim \\N(A \\mu_\\vx + b, \\Sigma_{\\vy|\\vx} + A \\Sigma_\\vx A^T) \n",
    "    \\end{align}\n",
    "    }\n",
    "    \\Rightarrow\n",
    "    \\boxed{\n",
    "    \\begin{align}\n",
    "    & \\text{Prediction of } \\vw\\\\\n",
    "    \\vw | \\vx, \\mathcal{D}  & \\sim \\N(\\vec{m}_N, S_N) \\\\\n",
    "    t|\\vw, \\vx, \\mathcal{D} & \\sim \\N(\\phi^T \\vw, \\beta^{-1}) \\\\\n",
    "    & \\Downarrow \\\\\n",
    "    t \\, | \\, \\vx, \\mathcal{D} & \\sim \\N(\\, \\phi(\\vx)^T \\vec{m}_n \\,, \\,{\\beta}^{-1} + \\phi(\\vx)^T S_N \\phi(\\vx) \\,)\n",
    "    \\end{align}\n",
    "    }\n",
    "    $$\n",
    "- Done!    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Predictive Distribution:  Example\n",
    "\n",
    "- Here the underlying true model we will use is $$t = \\sin(2 \\pi x) + \\epsilon$$ of which $\\epsilon$ represents some noise.\n",
    "\n",
    "- In regression, rather than polynomial basis function we used in previous lectures, we will use 9 Gaussian basis function\n",
    "    $$\n",
    "    \\phi_j(x) = \\exp\\left\\{ -\\frac{(x- \\mu_j)}{2s^2} \\right\\}\n",
    "    $$\n",
    "\n",
    "- We will still use streaming fashion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Predictive Distribution:  Example—One Observation\n",
    "- The observations are marked with blue circles in the plots.\n",
    "- Green curve is the true model $t = \\sin(2 \\pi x)$\n",
    "\n",
    "<center> <img src=\"images/predictive-n1.png\"  style=\"width:506px;height:190px;\"> </center>\n",
    "\n",
    "- **Left Plot**\n",
    "    - Red curve gives the mean value of prediction distribution $P(t | x, \\mathcal{D}_1)$, which is $\\phi(x)^T m_1$\n",
    "    - Red shaded region spans one standard deviation on either side of the mean\n",
    "    - Note that smallest deviation/variance occurs near observation point\n",
    "\n",
    "- **Right Plot**\n",
    "    - We first draw samples of $\\vw$ from $P(\\vw | \\mathcal{D}_1)$\n",
    "    - Then plot sample curves $y(x, \\vw) = \\vw^T \\phi(x)$\n",
    "    - If we draw infinite sample cures, their mean is just the red mean curve in left plot.\n",
    "- Here $\\mathcal{D}_i$ represents the first $i$ observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Predictive Distribution:  Example—Two Observations\n",
    "\n",
    "<center> <img src=\"images/predictive-n2.png\"  style=\"width:506px;height:190px;\"> </center>\n",
    "\n",
    "- **Left Plot**\n",
    "    - Red curve gives the mean value of prediction distribution $P(t | x, \\mathcal{D}_2)$, which is $\\phi(x)^T m_2$\n",
    "    - Red Mean Curve starts to resemble the true curve.\n",
    "    - Red shaded region has shrunk indicating variance becomes smaller\n",
    "\n",
    "- **Right Plot**\n",
    "    - We first draw samples of $\\vw$ from $P(\\vw | \\mathcal{D}_2)$\n",
    "    - Then plot sample curves $y(x, \\vw) = \\vw^T \\phi(x)$\n",
    "    - The sample curves are still quite scattered\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Predictive Distribution:  Example—Four Observations\n",
    "\n",
    "<center> <img src=\"images/predictive-n4.png\"  style=\"width:506px;height:190px;\"> </center>\n",
    "\n",
    "- **Left Plot**\n",
    "    - Red curve gives the mean value of prediction distribution $P(t | x, \\mathcal{D}_3)$, which is $\\phi(x)^T m_3$\n",
    "    - Red shaded region has further shrunk indicating smaller variance/uncertainty\n",
    "    - Red shaded region has small height near observation points\n",
    "    - Our observations have the effect of reducing the variance at their positions.\n",
    "    \n",
    "- **Right Plot**\n",
    "    - We first draw samples of $\\vw$ from $P(\\vw | \\mathcal{D}_2)$\n",
    "    - Then plot sample curves $y(x, \\vw) = \\vw^T \\phi(x)$\n",
    "    - The sample curves are still quite scattered\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Predictive Distribution:  Example—Twenty Five Observations\n",
    "\n",
    "<center> <img src=\"images/predictive-n25.png\"  style=\"width:506px;height:190px;\"> </center>\n",
    "\n",
    "- **Left Plot**\n",
    "    - Red curve gives the mean value of prediction distribution $P(t | x, \\mathcal{D}_{25})$, which is $\\phi(x)^T m_{25}$\n",
    "    - Red curve is already very close to the true curve!\n",
    "    - Red shaded region has shrunk greatly and variance has reduced greatly.\n",
    "    \n",
    "- **Right Plot**\n",
    "    - We first draw samples of $\\vw$ from $P(\\vw | \\mathcal{D}_{25})$\n",
    "    - Then plot sample curves $y(x, \\vw) = \\vw^T \\phi(x)$\n",
    "    - The sample curves almost converge to the true curve!\n",
    "\n",
    "- For details of these plots, please refer to **[PRML]**-P157."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Gaussian Processes\n",
    "\n",
    "> Taken from **[CS229]** and **[MLAPP]**\n",
    "\n",
    "- Now we will show you Bayesian linear regression is actually a Gaussian process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Gaussian Processes\n",
    "\n",
    "- **Motivation**: Here are some data points. What function did they come from?\n",
    "    - GPs are a nice way of expressing “priors on functions”\n",
    "    - Applications: Regression and Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Gaussian Processes:  Motivation\n",
    "\n",
    "- **Multivariate Gaussians** are useful for modeling *finite* collections of real-valued variables.\n",
    "    - Nice analytical properties\n",
    "    - Distribution over **random vectors**\n",
    "    - Easily model *correlations* between variables\n",
    "\n",
    "- **Gaussian Processes** extend Multivariate Gaussians to *infinite-sized* collections of real-valued variables.\n",
    "    - Distribution over **random functions**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Distributions over Functions:  Finite Domain\n",
    "\n",
    "- How can we parameterize probability distributions over functions?\n",
    "\n",
    "- Consider the following simple example:\n",
    "    - Let $\\mathcal{X} = \\{ x_1, \\dots, x_m \\}$ be any finite set.\n",
    "    - Let $\\mathcal{H}$ be the set of all functions $h : \\mathcal{X} \\mapsto \\R$.\n",
    "\n",
    "- For example, one function $h_0 \\in \\mathcal{H}$ is\n",
    "    $$\n",
    "    h_0(x_1) = 5 \\quad h_0(x_2) = 2.3 \\quad \\cdots \\quad h_0(x_{m-1}) = -\\pi \\quad h_0(x_m) = 8\n",
    "    $$\n",
    "\n",
    "- Then $h_0$ could be represented as a vector $\\vec{h_0} = [5, 2.3, \\dots, \\pi, 8]$\n",
    "\n",
    "- Any function $h \\in \\mathcal{H}$ can be represented as a vector."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Distributions over Functions:  Finite Domain\n",
    "\n",
    "- To specify a distribution over $\\mathcal{H}$, exploit the one-one mapping to $\\R^m$\n",
    "    - Assume a distribution over vectors, $\\vec{h} \\sim \\mathcal{N}(\\vec{\\mu}, \\sigma^2 I)$.\n",
    "\n",
    "- This **induces** a distribution over $\\mathcal{H}$ given by likelihoods at each *\"sample point\"*:\n",
    "    $$\n",
    "    P(h) = P(\\vec{h}) = \\prod_{k=1}^m \\frac{1}{\\sqrt{2\\pi} \\sigma} \\exp\\left[ -\\frac{1}{2\\sigma^2} ( f(x_k) - \\mu_k )^2 \\right]\n",
    "    $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Distributions over Functions:  Infinite Domain\n",
    "\n",
    "- A **stochastic process** is a collection of random variables, $f = \\{ f(x) \\}_{x \\in \\mathcal{X}}$ with index set $\\mathcal{X}$, e.g.\n",
    "    - Dirichlet Processes, Poisson Processes, etc.\n",
    "\n",
    "- A **Gaussian Process** is a stochastic process such that any finite subcollection of random variables has a multivariate Gaussian distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Gaussian Processes:  Definition\n",
    "\n",
    "- We say $f(\\cdot) \\sim \\mathcal{GP}(m, k)$ is drawn from a Gaussian process with\n",
    "    - mean function $m(\\cdot) : \\mathcal{X} \\mapsto \\R$\n",
    "    - covariance or kernel function $k(\\cdot, \\cdot) : \\mathcal{X} \\times \\mathcal{X} \\mapsto \\R$\n",
    "\n",
    " provided that for any finite set $\\{x_1, \\dots, x_m\\} \\subset \\mathcal{X}$, the associated random variables have distribution\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "f(x_1) \\\\ \\vdots \\\\ f(x_m)\n",
    "\\end{bmatrix}\n",
    "\\sim\n",
    "\\mathcal{N}\\left(\n",
    "\\begin{bmatrix}\n",
    "m(x_1) \\\\ \\vdots \\\\ m(x_m)\n",
    "\\end{bmatrix},\n",
    "\\begin{bmatrix}\n",
    "k(x_1, x_1) & \\cdots & k(x_1, x_m) \\\\\n",
    "\\vdots & \\ddots & \\vdots \\\\\n",
    "k(x_m, x_1) & \\cdots & k(x_m, x_m)\n",
    "\\end{bmatrix}\n",
    "\\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Gaussian Processes:  Interpretation\n",
    "\n",
    "- Intuitively, $f \\sim \\mathcal{GP}(m, k)$ is an \n",
    "    - extremely high-dimensional vector\n",
    "    - drawn from an extremely high-dimensional Gaussian\n",
    "\n",
    "- Each dimension corresponds to an element $x \\in \\mathcal{X}$,\n",
    "    - the corresponding component of the vector represents $f(x)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Gaussian Processes:  Mean and Covariance\n",
    "\n",
    "- The **mean function** $m(\\cdot) : \\mathcal{X} \\mapsto \\R$ can be any function.\n",
    "    - For most applications, we set $m \\equiv 0$.\n",
    "\n",
    "- The **covariance function** $k(\\cdot, \\cdot) : \\mathcal{X} \\times \\mathcal{X} \\mapsto \\R$ must be a valid kernel.\n",
    "    - $f(x)$ and $f(x')$ will have high covariance if $x$ and $x'$ are \"nearby\"\n",
    "    - Therefore, kernel controls **smoothness**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Gaussian Processes:  Example\n",
    "\n",
    "- When $m \\equiv 0$, the choice of kernel defines the prior.\n",
    "    - (Left) Gaussian Kernel $k(x, x') = \\exp(−\\theta ||x − x'||_2^2)$\n",
    "    - (Right) Exponential Kernel $k(x, x') = \\exp(−\\theta ||x − x'||_1)$\n",
    "\n",
    "- Samples from a Gaussian Process:\n",
    "\n",
    "<center><img src=\"images/gpleft.png\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Linear Regression Revisited\n",
    "\n",
    "- **Model:**  Assume $y \\approx w^T \\phi(x)$ is a combination of $M$ fixed basis functions.\n",
    "    $$\n",
    "    \\begin{align}\n",
    "    w &\\sim \\mathcal{N}(w_0, S_0) \\\\\n",
    "    y | x, w, \\beta &\\sim \\mathcal{N}(w^T \\phi(x_n), \\beta^{-1})\n",
    "    \\end{align}\n",
    "    $$\n",
    "\n",
    "- Given training points $x_1, \\dots, x_N$, what is the joint distribution $P(\\vec{y})$ of $y(x_1), \\dots, y(x_N)$?\n",
    "    $$\n",
    "    \\vec{y} = \\Phi w = \\begin{bmatrix} y(x_1) & \\cdots & y(x_N) \\end{bmatrix}^T\n",
    "    $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Linear Regression Revisited\n",
    "\n",
    "- Note $\\vec{y} = \\Phi w$ is a linear combination of Gaussians $w$, so is itself Gaussian!\n",
    "\n",
    "    $$\n",
    "    \\begin{align}\n",
    "    \\mathrm{E}[\\vec{y}]\n",
    "    &= \\Phi E[w] = 0 \\\\\n",
    "    \\mathrm{Cov}[\\vec{y}] \n",
    "    &= \\mathrm{E}[yy^T]\n",
    "    = \\Phi \\mathrm{E}[ww^T] \\Phi^T\n",
    "    = \\frac{1}{\\alpha} \\Phi \\Phi^T\n",
    "    = K\n",
    "    \\end{align}\n",
    "    $$\n",
    "\n",
    "- where $K = [ k(x_i, x_j) ]_{i,j} \\in \\R^{N \\times N}$ is the **Gram Matrix** over the training data with kernel\n",
    "    $$\n",
    "    k(x_i, x_j) = \\frac{1}{\\alpha} \\phi(x_i)^T \\phi(x_j)\n",
    "    $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Bayesian Linear Regression\n",
    "\n",
    "- So, Bayesian Kernel Linear Regression is a Gaussian Process!\n",
    "    - Kernel $k(\\cdot, \\cdot)$ is dot product in feature space.\n",
    "    $$\n",
    "    \\begin{align}\n",
    "    y &= f(x) + \\epsilon \\\\\n",
    "    f &\\sim \\mathcal{GP}(0, k(\\cdot, \\cdot)) \\\\\n",
    "    \\epsilon &\\sim \\mathcal{N}(0, \\sigma^2)\n",
    "    \\end{align}\n",
    "    $$\n",
    "\n",
    "> Features in BLR $\\iff$ Kernel functions for GPs\n",
    "\n",
    "- In general, $k(\\cdot, \\cdot)$ can be any valid kernel,\n",
    "- See the book for more details."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
